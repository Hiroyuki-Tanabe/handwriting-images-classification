{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ拡張24000枚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 1, 28, 28)\n",
      "(3000, 15)\n"
     ]
    }
   ],
   "source": [
    "# データの読み込み\n",
    "train_data = np.load(\"train_data.npy\")\n",
    "train_label = np.load(\"train_label.npy\")\n",
    "print(train_data.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 1, 28, 28)\n",
      "(600, 1, 28, 28)\n",
      "(2400, 15)\n",
      "(600, 15)\n"
     ]
    }
   ],
   "source": [
    "# ランダムスプリット\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_label,train_size=0.8)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.min()) / X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 28, 28, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "           rotation_range=0.1,\n",
    "           width_shift_range=0.2,\n",
    "           height_shift_range=0.2,\n",
    "           shear_range=0.2,\n",
    "           zoom_range=0.1,\n",
    "           horizontal_flip=False,\n",
    "           vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen2 = ImageDataGenerator(\n",
    "           rotation_range=0.1,\n",
    "           width_shift_range=0.1,\n",
    "           height_shift_range=0.1,\n",
    "           shear_range=0.1,\n",
    "           zoom_range=0.1,\n",
    "           horizontal_flip=False,\n",
    "           vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28, 1)\n",
      "(2400, 15)\n"
     ]
    }
   ],
   "source": [
    "X_gen = datagen.flow(X_train, y_train, batch_size=2400)\n",
    "X_gen_new, y_gen_new = X_gen.__next__()\n",
    "print(X_gen_new.shape)\n",
    "print(y_gen_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28, 1)\n",
      "(2400, 15)\n"
     ]
    }
   ],
   "source": [
    "X_gen2 = datagen2.flow(X_train, y_train, batch_size=2400)\n",
    "X_gen_new2, y_gen_new2 = X_gen2.__next__()\n",
    "print(X_gen_new2.shape)\n",
    "print(y_gen_new2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28, 1)\n",
      "(2400, 15)\n"
     ]
    }
   ],
   "source": [
    "X_gen3 = datagen.flow(X_train, y_train, batch_size=2400)\n",
    "X_gen_new3, y_gen_new3 = X_gen3.__next__()\n",
    "print(X_gen_new3.shape)\n",
    "print(y_gen_new3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28, 1)\n",
      "(2400, 15)\n"
     ]
    }
   ],
   "source": [
    "X_gen4 = datagen2.flow(X_train, y_train, batch_size=2400)\n",
    "X_gen_new4, y_gen_new4 = X_gen4.__next__()\n",
    "print(X_gen_new4.shape)\n",
    "print(y_gen_new4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28, 1)\n",
      "(2400, 15)\n"
     ]
    }
   ],
   "source": [
    "X_gen5 = datagen.flow(X_train, y_train, batch_size=2400)\n",
    "X_gen_new5, y_gen_new5 = X_gen5.__next__()\n",
    "print(X_gen_new5.shape)\n",
    "print(y_gen_new5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28, 1)\n",
      "(2400, 15)\n"
     ]
    }
   ],
   "source": [
    "X_gen6 = datagen2.flow(X_train, y_train, batch_size=2400)\n",
    "X_gen_new6, y_gen_new6 = X_gen6.__next__()\n",
    "print(X_gen_new6.shape)\n",
    "print(y_gen_new6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28, 1)\n",
      "(2400, 15)\n"
     ]
    }
   ],
   "source": [
    "X_gen7 = datagen.flow(X_train, y_train, batch_size=2400)\n",
    "X_gen_new7, y_gen_new7 = X_gen7.__next__()\n",
    "print(X_gen_new7.shape)\n",
    "print(y_gen_new7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28, 1)\n",
      "(2400, 15)\n"
     ]
    }
   ],
   "source": [
    "X_gen8 = datagen2.flow(X_train, y_train, batch_size=2400)\n",
    "X_gen_new8, y_gen_new8 = X_gen8.__next__()\n",
    "print(X_gen_new8.shape)\n",
    "print(y_gen_new8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28, 1)\n",
      "(2400, 15)\n"
     ]
    }
   ],
   "source": [
    "X_gen9 = datagen.flow(X_train, y_train, batch_size=2400)\n",
    "X_gen_new9, y_gen_new9 = X_gen9.__next__()\n",
    "print(X_gen_new9.shape)\n",
    "print(y_gen_new9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 28, 28, 1)\n",
      "(2400, 15)\n"
     ]
    }
   ],
   "source": [
    "X_gen10 = datagen2.flow(X_train, y_train, batch_size=2400)\n",
    "X_gen_new10, y_gen_new10 = X_gen10.__next__()\n",
    "print(X_gen_new10.shape)\n",
    "print(y_gen_new10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28800, 15)\n"
     ]
    }
   ],
   "source": [
    "y_train2 = np.concatenate([y_train, y_gen_new,y_gen_new2,y_gen_new3,y_gen_new4,y_gen_new5,y_gen_new6,y_gen_new7,y_gen_new8,y_gen_new9,y_gen_new10, y_train] )\n",
    "print(y_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28800, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train2 = np.concatenate([X_train, X_gen_new,X_gen_new2, X_gen_new3, X_gen_new4, X_gen_new5, X_gen_new6, X_gen_new7, X_gen_new8, X_gen_new9, X_gen_new10,X_train])\n",
    "print(X_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 28, 28, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(-1,28,28,1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', input_shape=(28, 28,1)))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(15, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28800 samples, validate on 600 samples\n",
      "Epoch 1/100\n",
      "28800/28800 [==============================] - 29s 1ms/step - loss: 0.0429 - acc: 0.9873 - val_loss: 0.5373 - val_acc: 0.9667\n",
      "Epoch 2/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0416 - acc: 0.9883 - val_loss: 0.5104 - val_acc: 0.9683\n",
      "Epoch 3/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0403 - acc: 0.9886 - val_loss: 0.5121 - val_acc: 0.9667\n",
      "Epoch 4/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0358 - acc: 0.9898 - val_loss: 0.4567 - val_acc: 0.9717\n",
      "Epoch 5/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0361 - acc: 0.9906 - val_loss: 0.5641 - val_acc: 0.9650\n",
      "Epoch 6/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0360 - acc: 0.9907 - val_loss: 0.6716 - val_acc: 0.9583\n",
      "Epoch 7/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0353 - acc: 0.9912 - val_loss: 0.6179 - val_acc: 0.9617\n",
      "Epoch 8/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0340 - acc: 0.9911 - val_loss: 0.5104 - val_acc: 0.9683\n",
      "Epoch 9/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0359 - acc: 0.9905 - val_loss: 0.6626 - val_acc: 0.9583\n",
      "Epoch 10/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0364 - acc: 0.9910 - val_loss: 0.3492 - val_acc: 0.9783\n",
      "Epoch 11/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0347 - acc: 0.9912 - val_loss: 0.4835 - val_acc: 0.9700\n",
      "Epoch 12/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0363 - acc: 0.9915 - val_loss: 0.4298 - val_acc: 0.9733\n",
      "Epoch 13/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0388 - acc: 0.9923 - val_loss: 0.6179 - val_acc: 0.9617\n",
      "Epoch 14/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0380 - acc: 0.9915 - val_loss: 0.5104 - val_acc: 0.9683\n",
      "Epoch 15/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0369 - acc: 0.9919 - val_loss: 0.3761 - val_acc: 0.9767\n",
      "Epoch 16/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0383 - acc: 0.9921 - val_loss: 0.5104 - val_acc: 0.9683\n",
      "Epoch 17/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0421 - acc: 0.9924 - val_loss: 0.4030 - val_acc: 0.9750\n",
      "Epoch 18/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0399 - acc: 0.9916 - val_loss: 0.4298 - val_acc: 0.9733\n",
      "Epoch 19/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0379 - acc: 0.9926 - val_loss: 0.6179 - val_acc: 0.9617\n",
      "Epoch 20/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0364 - acc: 0.9924 - val_loss: 0.4030 - val_acc: 0.9750\n",
      "Epoch 21/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0355 - acc: 0.9932 - val_loss: 0.5104 - val_acc: 0.9683\n",
      "Epoch 22/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0472 - acc: 0.9917 - val_loss: 0.2418 - val_acc: 0.9850\n",
      "Epoch 23/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0388 - acc: 0.9923 - val_loss: 0.3492 - val_acc: 0.9783\n",
      "Epoch 24/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0389 - acc: 0.9928 - val_loss: 0.3894 - val_acc: 0.9750\n",
      "Epoch 25/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0456 - acc: 0.9919 - val_loss: 0.3761 - val_acc: 0.9767\n",
      "Epoch 26/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0389 - acc: 0.9932 - val_loss: 0.4835 - val_acc: 0.9700\n",
      "Epoch 27/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0379 - acc: 0.9931 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 28/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0410 - acc: 0.9927 - val_loss: 0.6179 - val_acc: 0.9617\n",
      "Epoch 29/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0365 - acc: 0.9927 - val_loss: 0.4835 - val_acc: 0.9700\n",
      "Epoch 30/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0449 - acc: 0.9930 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 31/100\n",
      "28800/28800 [==============================] - 819s 28ms/step - loss: 0.0374 - acc: 0.9927 - val_loss: 0.4567 - val_acc: 0.9717\n",
      "Epoch 32/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0522 - acc: 0.9918 - val_loss: 0.9671 - val_acc: 0.9400\n",
      "Epoch 33/100\n",
      "28800/28800 [==============================] - 29s 1ms/step - loss: 0.0412 - acc: 0.9930 - val_loss: 0.9939 - val_acc: 0.9383\n",
      "Epoch 34/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0468 - acc: 0.9920 - val_loss: 0.6716 - val_acc: 0.9583\n",
      "Epoch 35/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0459 - acc: 0.9922 - val_loss: 0.8059 - val_acc: 0.9500\n",
      "Epoch 36/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0450 - acc: 0.9931 - val_loss: 0.5373 - val_acc: 0.9667\n",
      "Epoch 37/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0576 - acc: 0.9930 - val_loss: 0.5641 - val_acc: 0.9650\n",
      "Epoch 38/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0564 - acc: 0.9919 - val_loss: 1.1551 - val_acc: 0.9283\n",
      "Epoch 39/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0554 - acc: 0.9928 - val_loss: 0.6179 - val_acc: 0.9617\n",
      "Epoch 40/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0697 - acc: 0.9913 - val_loss: 0.6985 - val_acc: 0.9567\n",
      "Epoch 41/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0649 - acc: 0.9916 - val_loss: 1.5044 - val_acc: 0.9067\n",
      "Epoch 42/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0509 - acc: 0.9928 - val_loss: 0.6447 - val_acc: 0.9600\n",
      "Epoch 43/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0499 - acc: 0.9928 - val_loss: 0.5910 - val_acc: 0.9633\n",
      "Epoch 44/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0495 - acc: 0.9935 - val_loss: 0.4835 - val_acc: 0.9700\n",
      "Epoch 45/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0428 - acc: 0.9937 - val_loss: 0.4030 - val_acc: 0.9750\n",
      "Epoch 46/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0548 - acc: 0.9925 - val_loss: 0.2955 - val_acc: 0.9817\n",
      "Epoch 47/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0594 - acc: 0.9931 - val_loss: 0.5104 - val_acc: 0.9683\n",
      "Epoch 48/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0722 - acc: 0.9924 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 49/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0756 - acc: 0.9917 - val_loss: 0.3761 - val_acc: 0.9767\n",
      "Epoch 50/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0741 - acc: 0.9928 - val_loss: 0.6179 - val_acc: 0.9617\n",
      "Epoch 51/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0787 - acc: 0.9924 - val_loss: 0.2955 - val_acc: 0.9817\n",
      "Epoch 52/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0792 - acc: 0.9925 - val_loss: 0.5104 - val_acc: 0.9683\n",
      "Epoch 53/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0788 - acc: 0.9923 - val_loss: 0.5104 - val_acc: 0.9683\n",
      "Epoch 54/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0713 - acc: 0.9925 - val_loss: 0.3761 - val_acc: 0.9767\n",
      "Epoch 55/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0597 - acc: 0.9937 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 56/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0731 - acc: 0.9923 - val_loss: 0.4835 - val_acc: 0.9700\n",
      "Epoch 57/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0795 - acc: 0.9924 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 58/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.0764 - acc: 0.9929 - val_loss: 0.2955 - val_acc: 0.9817\n",
      "Epoch 59/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0744 - acc: 0.9935 - val_loss: 0.2955 - val_acc: 0.9817\n",
      "Epoch 60/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0768 - acc: 0.9935 - val_loss: 0.5373 - val_acc: 0.9667\n",
      "Epoch 61/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0773 - acc: 0.9933 - val_loss: 0.3492 - val_acc: 0.9783\n",
      "Epoch 62/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0846 - acc: 0.9927 - val_loss: 0.4567 - val_acc: 0.9717\n",
      "Epoch 63/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0783 - acc: 0.9928 - val_loss: 0.3761 - val_acc: 0.9767\n",
      "Epoch 64/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0829 - acc: 0.9927 - val_loss: 0.4567 - val_acc: 0.9717\n",
      "Epoch 65/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0707 - acc: 0.9933 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 66/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0749 - acc: 0.9938 - val_loss: 0.2149 - val_acc: 0.9867\n",
      "Epoch 67/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0734 - acc: 0.9939 - val_loss: 0.3492 - val_acc: 0.9783\n",
      "Epoch 68/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0643 - acc: 0.9942 - val_loss: 0.2955 - val_acc: 0.9817\n",
      "Epoch 69/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.0784 - acc: 0.9933 - val_loss: 0.1880 - val_acc: 0.9883\n",
      "Epoch 70/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.1002 - acc: 0.9926 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 71/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.1037 - acc: 0.9922 - val_loss: 0.3492 - val_acc: 0.9783\n",
      "Epoch 72/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.1234 - acc: 0.9913 - val_loss: 0.1880 - val_acc: 0.9883\n",
      "Epoch 73/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.1336 - acc: 0.9906 - val_loss: 0.1880 - val_acc: 0.9883\n",
      "Epoch 74/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.1514 - acc: 0.9896 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 75/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.1244 - acc: 0.9913 - val_loss: 0.3492 - val_acc: 0.9783\n",
      "Epoch 76/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.1177 - acc: 0.9913 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 77/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.1361 - acc: 0.9907 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 78/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.1366 - acc: 0.9907 - val_loss: 0.4567 - val_acc: 0.9717\n",
      "Epoch 79/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.1618 - acc: 0.9892 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 80/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.1568 - acc: 0.9894 - val_loss: 0.3761 - val_acc: 0.9767\n",
      "Epoch 81/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.1353 - acc: 0.9910 - val_loss: 0.5641 - val_acc: 0.9650\n",
      "Epoch 82/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.1490 - acc: 0.9904 - val_loss: 0.3761 - val_acc: 0.9767\n",
      "Epoch 83/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.1693 - acc: 0.9885 - val_loss: 0.4030 - val_acc: 0.9750\n",
      "Epoch 84/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.1529 - acc: 0.9898 - val_loss: 0.2955 - val_acc: 0.9817\n",
      "Epoch 85/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.1552 - acc: 0.9898 - val_loss: 0.3761 - val_acc: 0.9767\n",
      "Epoch 86/100\n",
      "28800/28800 [==============================] - 31s 1ms/step - loss: 0.2110 - acc: 0.9861 - val_loss: 0.3492 - val_acc: 0.9783\n",
      "Epoch 87/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.2184 - acc: 0.9858 - val_loss: 0.4030 - val_acc: 0.9750\n",
      "Epoch 88/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.1710 - acc: 0.9889 - val_loss: 0.2418 - val_acc: 0.9850\n",
      "Epoch 89/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.1949 - acc: 0.9875 - val_loss: 0.2686 - val_acc: 0.9833\n",
      "Epoch 90/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.2032 - acc: 0.9867 - val_loss: 0.2418 - val_acc: 0.9850\n",
      "Epoch 91/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.1829 - acc: 0.9883 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 92/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.1809 - acc: 0.9882 - val_loss: 0.3224 - val_acc: 0.9800\n",
      "Epoch 93/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.2145 - acc: 0.9863 - val_loss: 0.4567 - val_acc: 0.9717\n",
      "Epoch 94/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.2102 - acc: 0.9865 - val_loss: 0.4298 - val_acc: 0.9733\n",
      "Epoch 95/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.2173 - acc: 0.9861 - val_loss: 0.5373 - val_acc: 0.9667\n",
      "Epoch 96/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.1931 - acc: 0.9877 - val_loss: 0.2149 - val_acc: 0.9867\n",
      "Epoch 97/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.2955 - acc: 0.9813 - val_loss: 0.1880 - val_acc: 0.9883\n",
      "Epoch 98/100\n",
      "28800/28800 [==============================] - 32s 1ms/step - loss: 0.2283 - acc: 0.9854 - val_loss: 0.3492 - val_acc: 0.9783\n",
      "Epoch 99/100\n",
      "28800/28800 [==============================] - 1334s 46ms/step - loss: 0.2581 - acc: 0.9834 - val_loss: 0.3492 - val_acc: 0.9783\n",
      "Epoch 100/100\n",
      "28800/28800 [==============================] - 30s 1ms/step - loss: 0.3282 - acc: 0.9791 - val_loss: 0.2418 - val_acc: 0.9850\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train2, y_train2,\n",
    "                    batch_size= 64,\n",
    "                    epochs= 100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('katakana_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 15)                3855      \n",
      "=================================================================\n",
      "Total params: 92,287\n",
      "Trainable params: 92,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
